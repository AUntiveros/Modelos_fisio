{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e0dc00",
   "metadata": {},
   "source": [
    "# MODELO DE DETECCION DE LUGARES DE REPRODUCCION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2436170",
   "metadata": {},
   "source": [
    "# IMPORTACION DE LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c2b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6de576",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('image_discription.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1698fcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3762 entries, 0 to 3761\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   filename   3762 non-null   object\n",
      " 1   Question   3762 non-null   object\n",
      " 2   Response   3762 non-null   object\n",
      " 3   Reasoning  3762 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 117.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-2-_jpg.rf.755775e343a38a5816158f2cd0acf15e.jpg</td>\n",
       "      <td>Does the image show a potential mosquito breed...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The image contains tires submerged in water. D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-2-_jpg.rf.d165581a933c5b89485547ca00dd5360.jpg</td>\n",
       "      <td>Does this image contain any objects or areas l...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The image shows old tires partially submerged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-2-_jpg.rf.f6f585332e8d2f96d40eba243669f908.jpg</td>\n",
       "      <td>Does the image show a potential site for mosqu...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The image contains tires partially submerged i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1726484413702_jpg.rf.7fad42862fea19211aff69e8c...</td>\n",
       "      <td>Does this image depict a potential mosquito br...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The image shows a storm drain filled with stag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1726484413702_jpg.rf.ee84fec8843a83ea175261ea0...</td>\n",
       "      <td>Does the image show a potential mosquito breed...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The image shows a stagnant water collection po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0   1-2-_jpg.rf.755775e343a38a5816158f2cd0acf15e.jpg   \n",
       "1   1-2-_jpg.rf.d165581a933c5b89485547ca00dd5360.jpg   \n",
       "2   1-2-_jpg.rf.f6f585332e8d2f96d40eba243669f908.jpg   \n",
       "3  1726484413702_jpg.rf.7fad42862fea19211aff69e8c...   \n",
       "4  1726484413702_jpg.rf.ee84fec8843a83ea175261ea0...   \n",
       "\n",
       "                                            Question Response  \\\n",
       "0  Does the image show a potential mosquito breed...      Yes   \n",
       "1  Does this image contain any objects or areas l...      Yes   \n",
       "2  Does the image show a potential site for mosqu...      Yes   \n",
       "3  Does this image depict a potential mosquito br...      Yes   \n",
       "4  Does the image show a potential mosquito breed...      Yes   \n",
       "\n",
       "                                           Reasoning  \n",
       "0  The image contains tires submerged in water. D...  \n",
       "1  The image shows old tires partially submerged ...  \n",
       "2  The image contains tires partially submerged i...  \n",
       "3  The image shows a storm drain filled with stag...  \n",
       "4  The image shows a stagnant water collection po...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a71c48ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è user config directory '/home/leoni/.config/Ultralytics' is not writeable, defaulting to '/tmp' or CWD. Alternatively you can define a YOLO_CONFIG_DIR environment variable for this path.\n",
      "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/tmp/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 50.1MB/s 0.1s.1s<0.0s\n",
      "Ultralytics 8.3.195 üöÄ Python-3.12.3 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Breeding Place Detection/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/leoni/Proyecto_Modelos_Fisiologicos/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=False, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/tmp/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 9.7MB/s 0.1s\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,823 parameters, 3,011,807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 21.9MB/s 0.2s.2s<0.0s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.2¬±0.1 ms, read: 108.3¬±48.6 MB/s, size: 96.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/leoni/Proyecto_Modelos_Fisiologicos/Breeding Place Detection/train/labels... 3871 images, 36 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3871/3871 963.8it/s 4.0s0.1s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/leoni/Proyecto_Modelos_Fisiologicos/Breeding Place Detection/train/labels.cache\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 171, len(boxes) = 8125. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.1 ms, read: 193.6¬±62.6 MB/s, size: 97.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/leoni/Proyecto_Modelos_Fisiologicos/Breeding Place Detection/valid/labels... 371 images, 1 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 371/371 826.1it/s 0.4s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/leoni/Proyecto_Modelos_Fisiologicos/Breeding Place Detection/valid/labels.cache\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 7, len(boxes) = 731. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to /home/leoni/Proyecto_Modelos_Fisiologicos/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/home/leoni/Proyecto_Modelos_Fisiologicos/runs/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      2.03G      1.187      2.508       1.27         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 7.4it/s 32.5s<0.2s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      2.04G      1.203      1.715      1.253         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.6it/s 28.1s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      2.06G        1.2      1.498      1.266         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.8it/s 27.4ss<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      2.08G      1.184      1.316       1.25         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.7it/s 27.9s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50       2.1G      1.123      1.192      1.224         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 9.0it/s 26.9s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      2.11G      1.107      1.126      1.204         56        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.6it/s 28.2s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      2.13G      1.078      1.054      1.192         52        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 9.0it/s 27.0s0.2sss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      2.14G      1.044     0.9952      1.164         63        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.9it/s 27.2s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      2.16G      1.018     0.9397      1.155         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.8it/s 27.5s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      2.18G     0.9983     0.9079      1.139         61        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.7it/s 27.8s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50       2.2G      1.002     0.9005      1.141         79        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.8it/s 27.6ss<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      2.21G     0.9761     0.8438      1.122         43        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.5it/s 28.3s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      2.23G     0.9532     0.8229      1.111         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.6it/s 28.3s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      2.25G     0.9358     0.7996      1.104         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.3it/s 29.2s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      2.27G     0.9363     0.7769      1.104         49        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.3it/s 29.1s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      2.28G     0.9223     0.7617      1.098         64        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.8it/s 27.5s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50       2.3G     0.8866     0.7347      1.082         53        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.6it/s 28.2s<0.1ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      2.31G     0.8914     0.7182      1.072         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.5it/s 28.6s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      2.33G     0.8784     0.7014      1.072         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.6it/s 28.0s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      2.35G     0.8706     0.6897      1.067         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.5it/s 28.6s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      2.37G     0.8684     0.6875      1.066         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.5it/s 28.5s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      2.38G      0.854     0.6723      1.055         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.5it/s 28.5s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50       2.4G     0.8384     0.6398      1.048         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.8it/s 27.4s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      2.42G     0.8325     0.6335      1.045         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.7it/s 27.9s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      2.44G     0.8196     0.6244      1.039         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.6it/s 28.2s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      2.45G     0.8147     0.6231      1.038         64        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.5it/s 28.4s<0.1ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      2.47G     0.8042     0.5968      1.028         53        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.4it/s 28.7s0.2sss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      2.49G     0.7968     0.5948      1.025         36        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.5it/s 28.3s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50       2.5G     0.7878     0.5851      1.022         50        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.3it/s 29.2s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      2.52G     0.7729     0.5679      1.019         54        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.4it/s 28.9s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      2.54G      0.772     0.5659      1.013         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.6it/s 28.0s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      2.55G     0.7559     0.5525      1.008         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.5it/s 28.6s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      2.57G     0.7557     0.5467      1.002         46        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.3it/s 29.3s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      2.59G     0.7371      0.529          1         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.3it/s 29.1s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      2.61G     0.7234      0.527     0.9911         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.3it/s 29.2s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      2.62G     0.7318     0.5215      0.996         42        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.4it/s 28.7s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      2.64G     0.7164     0.5093     0.9923         49        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 7.9it/s 30.7s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      2.66G     0.7102     0.5041     0.9857         58        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.2it/s 29.4s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      2.68G     0.7028     0.4963     0.9844         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 7.8it/s 30.9s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      2.69G     0.6892     0.4892     0.9817         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.1it/s 29.8s<0.1s\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      2.71G     0.6387     0.4146     0.9265         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.2it/s 29.7s0.2sss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      2.72G     0.6188     0.3876      0.918         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.0it/s 30.4s<0.1ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      2.74G     0.6056     0.3763     0.9116         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 7.9it/s 30.7s<0.1ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      2.76G      0.592     0.3687      0.906         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.2it/s 29.5s<0.1ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      2.78G     0.5782     0.3572     0.9012         39        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.2it/s 29.5s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      2.79G     0.5757     0.3546     0.9009         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.0it/s 30.4s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      2.81G      0.564     0.3482     0.8958         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.3it/s 29.1s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      2.83G     0.5582     0.3405     0.8897         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.4it/s 28.7s<0.1s\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      2.85G     0.5473     0.3354     0.8872         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.2it/s 29.6s0.2ss\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      2.86G     0.5455     0.3358     0.8856         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 242/242 8.8it/s 27.5s<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 2.2it/s 5.5s0.3s\n",
      "                   all        371        731       0.92      0.863      0.924      0.727\n",
      "\n",
      "50 epochs completed in 0.404 hours.\n",
      "Optimizer stripped from /home/leoni/Proyecto_Modelos_Fisiologicos/runs/detect/train/weights/last.pt, 6.3MB\n",
      "Optimizer stripped from /home/leoni/Proyecto_Modelos_Fisiologicos/runs/detect/train/weights/best.pt, 6.3MB\n",
      "\n",
      "Validating /home/leoni/Proyecto_Modelos_Fisiologicos/runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.195 üöÄ Python-3.12.3 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 4.2it/s 2.8s0.2s\n",
      "                   all        371        731       0.92      0.863      0.924      0.728\n",
      "                Bottle         59        100       0.89       0.88      0.915      0.723\n",
      "       Coconut-Exocarp         92        171      0.932      0.968      0.979      0.784\n",
      "           Drain-Inlet        110        135       0.96      0.882      0.966      0.651\n",
      "                  Tire         62        119      0.945      0.815      0.904      0.783\n",
      "                  Vase         92        206      0.873       0.77      0.856      0.698\n",
      "Speed: 0.2ms preprocess, 1.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/leoni/Proyecto_Modelos_Fisiologicos/runs/detect/train\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instala ultralytics si no lo tienes\n",
    "\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Ruta al archivo de configuraci√≥n de datos YOLO\n",
    "# Crea un archivo data.yaml en la carpeta 'Breeding Place Detection' con la estructura:\n",
    "# train: Breeding Place Detection/images/train\n",
    "# val: Breeding Place Detection/images/val\n",
    "# nc: <n√∫mero de clases>\n",
    "# names: [clase1, clase2, ...]\n",
    "\n",
    "# Entrena el modelo YOLO usando solo la data de train\n",
    "model = YOLO('yolov8n.pt')  # Puedes cambiar a yolov8s.pt, yolov8m.pt, etc.\n",
    "\n",
    "results = model.train(\n",
    "    data='Breeding Place Detection/data.yaml',  # Ruta al archivo de configuraci√≥n\n",
    "    epochs=50,                                  # N√∫mero de √©pocas\n",
    "    imgsz=640,                                  # Tama√±o de imagen\n",
    "    batch=16,                                   # Tama√±o de batch\n",
    "    workers=2,                                  # N√∫mero de workers\n",
    "    val=False                                   # Solo usa train, no valida\n",
    ")\n",
    "\n",
    "# Guarda el modelo entrenado\n",
    "model.save('Breeding_Place_Detection_YOLO.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a2551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.195 üöÄ Python-3.12.3 torch-2.8.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 72 layers, 3,006,623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1060.3¬±761.8 MB/s, size: 106.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/leoni/Proyecto_Modelos_Fisiologicos/Breeding Place Detection/valid/labels.cache... 371 images, 1 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 371/371 513.1Kit/s 0.0s\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 7, len(boxes) = 731. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 24/24 6.3it/s 3.8s0.2s\n",
      "                   all        371        731      0.919      0.862      0.924      0.727\n",
      "                Bottle         59        100       0.89       0.88      0.915      0.721\n",
      "       Coconut-Exocarp         92        171      0.929      0.965      0.979      0.786\n",
      "           Drain-Inlet        110        135       0.96      0.882      0.967      0.647\n",
      "                  Tire         62        119      0.945      0.815      0.904      0.785\n",
      "                  Vase         92        206      0.873      0.769      0.857      0.698\n",
      "Speed: 1.6ms preprocess, 3.5ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m/home/leoni/Proyecto_Modelos_Fisiologicos/runs/detect/train2\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DetMetrics' object has no attribute 'metrics'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n\n    Attributes:\n        names (dict[int, str]): A dictionary of class names.\n        box (Metric): An instance of the Metric class for storing detection results.\n        speed (dict[str, float]): A dictionary for storing execution times of different parts of the detection process.\n        task (str): The task type, set to 'detect'.\n        stats (dict[str, list]): A dictionary containing lists for true positives, confidence scores, predicted classes, target classes, and target images.\n        nt_per_class: Number of targets per class.\n        nt_per_image: Number of targets per image.\n\n    Methods:\n        update_stats: Update statistics by appending new values to existing stat collections.\n        process: Process predicted results for object detection and update metrics.\n        clear_stats: Clear the stored statistics.\n        keys: Return a list of keys for accessing specific metrics.\n        mean_results: Calculate mean of detected objects & return precision, recall, mAP50, and mAP50-95.\n        class_result: Return the result of evaluating the performance of an object detection model on a specific class.\n        maps: Return mean Average Precision (mAP) scores per class.\n        fitness: Return the fitness of box object.\n        ap_class_index: Return the average precision index per class.\n        results_dict: Return dictionary of computed performance metrics and statistics.\n        curves: Return a list of curves for accessing specific metrics curves.\n        curves_results: Return a list of computed performance metrics and statistics.\n        summary: Generate a summarized representation of per-class detection metrics as a list of dictionaries.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m results = model.val(data=\u001b[33m'\u001b[39m\u001b[33mBreeding Place Detection/data.yaml\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Muestra las m√©tricas principales\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrecisi√≥n (mAP50):\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmAP50\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrecisi√≥n (mAP50-95):\u001b[39m\u001b[33m\"\u001b[39m, results.metrics[\u001b[33m'\u001b[39m\u001b[33mmAP50-95\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrecisi√≥n por clase:\u001b[39m\u001b[33m\"\u001b[39m, results.metrics[\u001b[33m'\u001b[39m\u001b[33map\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Proyecto_Modelos_Fisiologicos/.venv/lib/python3.12/site-packages/ultralytics/utils/__init__.py:274\u001b[39m, in \u001b[36mSimpleClass.__getattr__\u001b[39m\u001b[34m(self, attr)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Provide a custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[32m    273\u001b[39m name = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DetMetrics' object has no attribute 'metrics'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n\n    Attributes:\n        names (dict[int, str]): A dictionary of class names.\n        box (Metric): An instance of the Metric class for storing detection results.\n        speed (dict[str, float]): A dictionary for storing execution times of different parts of the detection process.\n        task (str): The task type, set to 'detect'.\n        stats (dict[str, list]): A dictionary containing lists for true positives, confidence scores, predicted classes, target classes, and target images.\n        nt_per_class: Number of targets per class.\n        nt_per_image: Number of targets per image.\n\n    Methods:\n        update_stats: Update statistics by appending new values to existing stat collections.\n        process: Process predicted results for object detection and update metrics.\n        clear_stats: Clear the stored statistics.\n        keys: Return a list of keys for accessing specific metrics.\n        mean_results: Calculate mean of detected objects & return precision, recall, mAP50, and mAP50-95.\n        class_result: Return the result of evaluating the performance of an object detection model on a specific class.\n        maps: Return mean Average Precision (mAP) scores per class.\n        fitness: Return the fitness of box object.\n        ap_class_index: Return the average precision index per class.\n        results_dict: Return dictionary of computed performance metrics and statistics.\n        curves: Return a list of curves for accessing specific metrics curves.\n        curves_results: Return a list of computed performance metrics and statistics.\n        summary: Generate a summarized representation of per-class detection metrics as a list of dictionaries.\n    "
     ]
    }
   ],
   "source": [
    "# Eval√∫a el modelo usando el conjunto de validaci√≥n\n",
    "# Eval√∫a el modelo usando el conjunto de validaci√≥n\n",
    "results = model.val(data='Breeding Place Detection/data.yaml')\n",
    "\n",
    "# Obt√©n el diccionario de m√©tricas\n",
    "metrics = results.results_dict\n",
    "\n",
    "# Muestra las m√©tricas principales\n",
    "print(\"Precisi√≥n (mAP50):\", metrics['metrics/mAP_0.5'])\n",
    "print(\"Precisi√≥n (mAP50-95):\", metrics['metrics/mAP_0.5:0.95'])\n",
    "print(\"Precisi√≥n por clase:\", metrics['metrics/AP_per_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fd96f",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
